# ğŸ¤– RAG-Powered PDF Chatbot

## ğŸ“– Project Description
The **RAG-Powered PDF Chatbot** is an AI application that allows users to **upload a PDF file** and then **ask natural language questions** about its content.  
Using **Retrieval-Augmented Generation (RAG)**, the chatbot retrieves the most relevant information from the document and generates accurate, context-aware answers.  

This project is designed to help users quickly extract insights from long documents such as research papers, reports, and manuals â€” eliminating the need to read them line by line.

---

## ğŸ’¡ Key Features
- ğŸ“‚ **Upload any PDF file** (reports, research papers, or e-books)
- ğŸ§  **Retrieval-Augmented Generation (RAG)** for context-based question answering
- âš¡ **FAISS Vector Database** for efficient semantic search
- ğŸ”— **LangChain Integration** for document chunking, embeddings, and retrieval
- ğŸ’¬ **Interactive Streamlit Interface** for smooth user interaction
- ğŸŒ **Pyngrok Deployment** for public access and live testing

---

## ğŸ—ï¸ System Architecture

```mermaid
flowchart TD
A[ğŸ“„ PDF File Upload] --> B[ğŸ” Text Extraction & Chunking]
B --> C[ğŸ§© Embedding Creation using LLM Embeddings]
C --> D[ğŸ—‚ï¸ Store Embeddings in FAISS Vector DB]
D --> E[â“ User Asks a Question]
E --> F[ğŸ” Retrieve Most Relevant Chunks]
F --> G[ğŸ§  LLM Generates Final Answer]
G --> H[ğŸ’¬ Streamlit UI Displays Response]
```

---

# ğŸ¤– RAG-Powered PDF Chatbot

## ğŸ› ï¸ Tools & Technologies

| Category | Tools / Libraries |
|-----------|------------------|
| ğŸ§  **LLM & Framework** | LangChain, OpenAI API |
| ğŸ—‚ï¸ **Vector Database** | FAISS |
| ğŸ’¬ **UI** | Streamlit |
| ğŸŒ **Deployment** | Pyngrok |
| ğŸ **Language** | Python |
| ğŸ“š **Others** | PyPDF2, tiktoken, NumPy, Pandas |

---

## âš™ï¸ How It Works

1. ğŸ§¾ **Upload PDF** â€” The user uploads a document via the Streamlit interface.  
2. ğŸ” **Extract & Chunk** â€” The PDF text is extracted and split into smaller, meaningful chunks.  
3. ğŸ§© **Embedding Creation** â€” Each chunk is converted into a numerical embedding using OpenAI embeddings.  
4. ğŸ—‚ï¸ **Vector Storage** â€” The embeddings are stored in a FAISS vector database for efficient similarity search.  
5. ğŸ’¬ **Question & Answer** â€” When a user asks a question, the system retrieves the most relevant chunks and passes them to the LLM to generate a context-aware, accurate answer.

---

## ğŸ§ª Example Interaction

**User Uploads:** `Artificial_Intelligence_Research_Paper.pdf`  
**User Asks:**  
> "What are the main applications of AI mentioned in this paper?"

**Chatbot Responds:**  
> "The paper highlights key AI applications including autonomous vehicles, medical diagnostics, and predictive data analytics."

---

## ğŸ’¡ Summary

This project demonstrates the power of **Retrieval-Augmented Generation (RAG)** by combining **LangChain**, **FAISS**, and **OpenAI LLMs** to build an intelligent PDF assistant.  
It allows users to **instantly query large documents** and get **accurate, summarized answers** without manual searching â€” all through an intuitive **Streamlit interface**.

---

## ğŸš€ Next Steps
- ğŸŒ Add **multilingual PDF support**
- ğŸ¤ Integrate with **Chroma or Pinecone** for scalable vector storage
- ğŸ“± Deploy a **web version** via Streamlit Cloud or Render
- âš¡ Improve response speed using **Distil models**
